{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, Reshape\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return np.array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"fra.txt\"\n",
    "doc = load_doc(filename)\n",
    "pairs = to_pairs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose sample size\n",
    "n_train = 20000\n",
    "clean_pairs = clean_data(pairs)[0:n_train, :]\n",
    "# clean_pairs = clean_data(pairs)\n",
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = clean_pairs[:, 1]\n",
    "\n",
    "# create word level input sequence\n",
    "input_sequences = []\n",
    "for t in input_texts:\n",
    "    input_sequences.append(t.split())\n",
    "# create word level target sequence\n",
    "target_sequences = []\n",
    "for t in target_texts:\n",
    "    cur_seq = ['\\t']\n",
    "    cur_seq.extend(t.split())\n",
    "    cur_seq.append('\\n')\n",
    "    target_sequences.append(cur_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max(len(line) for line in input_sequences)\n",
    "max_decoder_seq_length = max(len(line) for line in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (20000,)\n",
      "Length of target_texts: (20000,)\n",
      "max length of input  sentences: 5\n",
      "max length of target sentences: 14\n"
     ]
    }
   ],
   "source": [
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_sequences, target_sequences, test_size=0.2, random_state=42)\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, X_train)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (16000, 5)\n",
      "shape of input_token_index: 3220\n",
      "shape of decoder_input_seq: (16000, 14)\n",
      "shape of target_token_index: 6200\n"
     ]
    }
   ],
   "source": [
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 3221\n",
      "num_decoder_tokens: 6201\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(encoder_input_seq)\n",
    "Y = np.array(decoder_input_seq)\n",
    "X_onehot = np.array(list(map(lambda x: to_categorical(x, num_classes=num_encoder_tokens),X)))\n",
    "Y_onehot = np.array(list(map(lambda x: to_categorical(x, num_classes=num_decoder_tokens),Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 5, 3221)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 14, 6201)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrain word embedding vectors 'glove'\n",
    "# use 50 dimention as  \n",
    "with open(\"glove.6B/glove.6B.50d.txt\", 'r') as f:\n",
    "    words = set()\n",
    "    word_to_vec = {}\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        cur_word = line[0]\n",
    "        words.add(cur_word)\n",
    "        word_to_vec[cur_word] = np.array(line[1:], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(word_to_vec, num_encoder_tokens):\n",
    "    vocab_len = num_encoder_tokens\n",
    "    embedding_dim = 50\n",
    "    embedding_matrix = np.zeros((vocab_len, embedding_dim)) # initialize embedding matrix\n",
    "    \n",
    "    for word, index in input_token_index.items():\n",
    "        word_vector = word_to_vec.get(word, np.zeros(embedding_dim))\n",
    "        embedding_matrix[index, :] = word_vector\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_len, embedding_dim, trainable=False)\n",
    "    embedding_layer.build((None, ))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = pretrain(word_to_vec, num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3221)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_onehot.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_x = Input(shape=(X_onehot.shape[1:]), name='encoder_input_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_x = Input(shape=(Y_onehot.shape[1:]), name='decoder_input_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 14, 6201])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize softmax function\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"\n",
    "    Softmax activation function.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize layers\n",
    "repeator = RepeatVector(max_encoder_seq_length)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor_tanh = Dense(32, activation = \"tanh\")\n",
    "densor_relu = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Attention mechanism，return weighted Context Vector\n",
    "    \n",
    "    @param a: BiRNN hidden state\n",
    "    @param s_prev: Decoder LSTM last hidden output\n",
    "    \n",
    "    Returns:\n",
    "    context: weighted Context Vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # repeat max_encoder_seq_length times \n",
    "    s_prev = repeator(s_prev)\n",
    "    # connect BiRNN hidden state and s_prev\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # calculate energies\n",
    "    e = densor_tanh(concat)\n",
    "    energies = densor_relu(e)\n",
    "    # compute weights\n",
    "    alphas = activator(energies)\n",
    "    # weighted Context Vector\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32 # The hidden size of Bi-LSTM\n",
    "n_s = 128 # The hidden size of LSTM in Decoder\n",
    "decoder_LSTM_cell = LSTM(n_s, return_state=True)\n",
    "output_layer = Dense(num_decoder_tokens, activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapor = Reshape((1, num_decoder_tokens))\n",
    "concator = Concatenate(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(max_encoder_seq_length, max_decoder_seq_length, n_a, n_s, num_encoder_tokens, num_decoder_tokens):\n",
    "    X = Input(shape=(max_encoder_seq_length,))\n",
    "    # Embedding layer\n",
    "    embed = embedding_layer(X)\n",
    "    # Decoder initialize\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    \n",
    "    # Decoder input for LSTM layer\n",
    "    out0 = Input(shape=(num_decoder_tokens, ), name='out0')\n",
    "    out = reshapor(out0)\n",
    "    \n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # save output results\n",
    "    outputs = []\n",
    "    \n",
    "    # 定义Bi-LSTM\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(embed)\n",
    "    \n",
    "    # Decoder, iterate max_decoder_seq_length rounds, each iteration generates one result\n",
    "    for t in range(max_decoder_seq_length):\n",
    "    \n",
    "        # get Context Vector\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # concat Context Vector and the previous translated result\n",
    "        context = concator([context, reshapor(out)])\n",
    "        s, _, c = decoder_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # connect lstm output and dense layer\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # save output result\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model([X, s0, c0, out0], outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(max_encoder_seq_length, max_decoder_seq_length, n_a, n_s, num_encoder_tokens, num_decoder_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 5, 50)        161050      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 5, 64)        21248       embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 5, 128)       0           s0[0][0]                         \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "                                                                 lstm_3[2][0]                     \n",
      "                                                                 lstm_3[3][0]                     \n",
      "                                                                 lstm_3[4][0]                     \n",
      "                                                                 lstm_3[5][0]                     \n",
      "                                                                 lstm_3[6][0]                     \n",
      "                                                                 lstm_3[7][0]                     \n",
      "                                                                 lstm_3[8][0]                     \n",
      "                                                                 lstm_3[9][0]                     \n",
      "                                                                 lstm_3[10][0]                    \n",
      "                                                                 lstm_3[11][0]                    \n",
      "                                                                 lstm_3[12][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 192)       0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[10][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[11][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[12][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[13][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5, 32)        6176        concatenate_2[0][0]              \n",
      "                                                                 concatenate_2[1][0]              \n",
      "                                                                 concatenate_2[2][0]              \n",
      "                                                                 concatenate_2[3][0]              \n",
      "                                                                 concatenate_2[4][0]              \n",
      "                                                                 concatenate_2[5][0]              \n",
      "                                                                 concatenate_2[6][0]              \n",
      "                                                                 concatenate_2[7][0]              \n",
      "                                                                 concatenate_2[8][0]              \n",
      "                                                                 concatenate_2[9][0]              \n",
      "                                                                 concatenate_2[10][0]             \n",
      "                                                                 concatenate_2[11][0]             \n",
      "                                                                 concatenate_2[12][0]             \n",
      "                                                                 concatenate_2[13][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5, 1)         33          dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 dense_3[2][0]                    \n",
      "                                                                 dense_3[3][0]                    \n",
      "                                                                 dense_3[4][0]                    \n",
      "                                                                 dense_3[5][0]                    \n",
      "                                                                 dense_3[6][0]                    \n",
      "                                                                 dense_3[7][0]                    \n",
      "                                                                 dense_3[8][0]                    \n",
      "                                                                 dense_3[9][0]                    \n",
      "                                                                 dense_3[10][0]                   \n",
      "                                                                 dense_3[11][0]                   \n",
      "                                                                 dense_3[12][0]                   \n",
      "                                                                 dense_3[13][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out0 (InputLayer)               [(None, 6201)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 5, 1)         0           dense_4[0][0]                    \n",
      "                                                                 dense_4[1][0]                    \n",
      "                                                                 dense_4[2][0]                    \n",
      "                                                                 dense_4[3][0]                    \n",
      "                                                                 dense_4[4][0]                    \n",
      "                                                                 dense_4[5][0]                    \n",
      "                                                                 dense_4[6][0]                    \n",
      "                                                                 dense_4[7][0]                    \n",
      "                                                                 dense_4[8][0]                    \n",
      "                                                                 dense_4[9][0]                    \n",
      "                                                                 dense_4[10][0]                   \n",
      "                                                                 dense_4[11][0]                   \n",
      "                                                                 dense_4[12][0]                   \n",
      "                                                                 dense_4[13][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 6201)      0           out0[0][0]                       \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "                                                                 dense_5[2][0]                    \n",
      "                                                                 dense_5[3][0]                    \n",
      "                                                                 dense_5[4][0]                    \n",
      "                                                                 dense_5[5][0]                    \n",
      "                                                                 dense_5[6][0]                    \n",
      "                                                                 dense_5[7][0]                    \n",
      "                                                                 dense_5[8][0]                    \n",
      "                                                                 dense_5[9][0]                    \n",
      "                                                                 dense_5[10][0]                   \n",
      "                                                                 dense_5[11][0]                   \n",
      "                                                                 dense_5[12][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 6265)      0           dot_1[0][0]                      \n",
      "                                                                 reshape_1[1][0]                  \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 reshape_1[2][0]                  \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 reshape_1[3][0]                  \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 reshape_1[4][0]                  \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 reshape_1[5][0]                  \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 reshape_1[6][0]                  \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 reshape_1[7][0]                  \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 reshape_1[8][0]                  \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 reshape_1[9][0]                  \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 reshape_1[10][0]                 \n",
      "                                                                 dot_1[10][0]                     \n",
      "                                                                 reshape_1[11][0]                 \n",
      "                                                                 dot_1[11][0]                     \n",
      "                                                                 reshape_1[12][0]                 \n",
      "                                                                 dot_1[12][0]                     \n",
      "                                                                 reshape_1[13][0]                 \n",
      "                                                                 dot_1[13][0]                     \n",
      "                                                                 reshape_1[14][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 128), (None, 3273728     concatenate_3[0][0]              \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_3[1][0]              \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "                                                                 concatenate_3[2][0]              \n",
      "                                                                 lstm_3[1][0]                     \n",
      "                                                                 lstm_3[1][2]                     \n",
      "                                                                 concatenate_3[3][0]              \n",
      "                                                                 lstm_3[2][0]                     \n",
      "                                                                 lstm_3[2][2]                     \n",
      "                                                                 concatenate_3[4][0]              \n",
      "                                                                 lstm_3[3][0]                     \n",
      "                                                                 lstm_3[3][2]                     \n",
      "                                                                 concatenate_3[5][0]              \n",
      "                                                                 lstm_3[4][0]                     \n",
      "                                                                 lstm_3[4][2]                     \n",
      "                                                                 concatenate_3[6][0]              \n",
      "                                                                 lstm_3[5][0]                     \n",
      "                                                                 lstm_3[5][2]                     \n",
      "                                                                 concatenate_3[7][0]              \n",
      "                                                                 lstm_3[6][0]                     \n",
      "                                                                 lstm_3[6][2]                     \n",
      "                                                                 concatenate_3[8][0]              \n",
      "                                                                 lstm_3[7][0]                     \n",
      "                                                                 lstm_3[7][2]                     \n",
      "                                                                 concatenate_3[9][0]              \n",
      "                                                                 lstm_3[8][0]                     \n",
      "                                                                 lstm_3[8][2]                     \n",
      "                                                                 concatenate_3[10][0]             \n",
      "                                                                 lstm_3[9][0]                     \n",
      "                                                                 lstm_3[9][2]                     \n",
      "                                                                 concatenate_3[11][0]             \n",
      "                                                                 lstm_3[10][0]                    \n",
      "                                                                 lstm_3[10][2]                    \n",
      "                                                                 concatenate_3[12][0]             \n",
      "                                                                 lstm_3[11][0]                    \n",
      "                                                                 lstm_3[11][2]                    \n",
      "                                                                 concatenate_3[13][0]             \n",
      "                                                                 lstm_3[12][0]                    \n",
      "                                                                 lstm_3[12][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6201)         799929      lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "                                                                 lstm_3[2][0]                     \n",
      "                                                                 lstm_3[3][0]                     \n",
      "                                                                 lstm_3[4][0]                     \n",
      "                                                                 lstm_3[5][0]                     \n",
      "                                                                 lstm_3[6][0]                     \n",
      "                                                                 lstm_3[7][0]                     \n",
      "                                                                 lstm_3[8][0]                     \n",
      "                                                                 lstm_3[9][0]                     \n",
      "                                                                 lstm_3[10][0]                    \n",
      "                                                                 lstm_3[11][0]                    \n",
      "                                                                 lstm_3[12][0]                    \n",
      "                                                                 lstm_3[13][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,262,164\n",
      "Trainable params: 4,101,114\n",
      "Non-trainable params: 161,050\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001),\n",
    "                    metrics=['accuracy'],\n",
    "                    loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0] # num of training sample\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "out0 = np.zeros((m, num_decoder_tokens))\n",
    "outputs = list(Y_onehot.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 150s 9ms/sample - loss: 34.4163 - dense_5_loss: 0.7818 - dense_5_1_loss: 5.7422 - dense_5_2_loss: 7.3896 - dense_5_3_loss: 7.6430 - dense_5_4_loss: 5.2890 - dense_5_5_loss: 2.9330 - dense_5_6_loss: 1.4330 - dense_5_7_loss: 0.7143 - dense_5_8_loss: 0.4949 - dense_5_9_loss: 0.4209 - dense_5_10_loss: 0.4015 - dense_5_11_loss: 0.3938 - dense_5_12_loss: 0.3907 - dense_5_13_loss: 0.3885 - dense_5_accuracy: 0.8240 - dense_5_1_accuracy: 0.1142 - dense_5_2_accuracy: 0.0235 - dense_5_3_accuracy: 0.0926 - dense_5_4_accuracy: 0.2511 - dense_5_5_accuracy: 0.5231 - dense_5_6_accuracy: 0.7929 - dense_5_7_accuracy: 0.9298 - dense_5_8_accuracy: 0.9772 - dense_5_9_accuracy: 0.9868 - dense_5_10_accuracy: 0.9907 - dense_5_11_accuracy: 0.9914 - dense_5_12_accuracy: 0.9918 - dense_5_13_accuracy: 0.9919\n",
      "Epoch 2/2\n",
      " 4736/16000 [=======>......................] - ETA: 1:20 - loss: 25.6683 - dense_5_loss: 0.0062 - dense_5_1_loss: 4.5930 - dense_5_2_loss: 6.1649 - dense_5_3_loss: 6.4549 - dense_5_4_loss: 4.3874 - dense_5_5_loss: 2.3686 - dense_5_6_loss: 1.0512 - dense_5_7_loss: 0.3749 - dense_5_8_loss: 0.1394 - dense_5_9_loss: 0.0573 - dense_5_10_loss: 0.0278 - dense_5_11_loss: 0.0167 - dense_5_12_loss: 0.0131 - dense_5_13_loss: 0.0130 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 0.1934 - dense_5_2_accuracy: 0.0712 - dense_5_3_accuracy: 0.1470 - dense_5_4_accuracy: 0.3680 - dense_5_5_accuracy: 0.5731 - dense_5_6_accuracy: 0.7988 - dense_5_7_accuracy: 0.9345 - dense_5_8_accuracy: 0.9840 - dense_5_9_accuracy: 0.9937 - dense_5_10_accuracy: 0.9983 - dense_5_11_accuracy: 0.9994 - dense_5_12_accuracy: 1.0000 - dense_5_13_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit([X, s0, c0, out0], outputs, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
