{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dropout\n",
    "from string import punctuation\n",
    "from keras.models import Sequential\n",
    "from keras import layers, regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers, layers\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    f = open(path)\n",
    "    context = f.read().strip()\n",
    "    f.close()\n",
    "    raw = context.split('\\n')\n",
    "    sentences = []\n",
    "    for sentence in raw:\n",
    "        cur = sentence.split()\n",
    "        if len(cur) > 4:\n",
    "             sentences.append(cur)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def split_data(s,l,X_train, X_test, Y_train, Y_test):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(s, l, test_size=0.2, random_state=42)\n",
    "    X_train.extend(x_train)\n",
    "    X_test.extend(x_test)\n",
    "    Y_train.extend(y_train)\n",
    "    Y_test.extend(y_test)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def preprocess():\n",
    "    authors =  ['Fyodor Dostoyevsky', 'Conan Doyle', 'Jane Austen']\n",
    "    p1, p2, p3 = ['data/28054-0.txt', 'data/pg1661.txt', 'data/pg31100.txt']\n",
    "\n",
    "    # manully remove headers \n",
    "    s1 = get_data(p1)[91:]\n",
    "    s2 = get_data(p2)[23:]\n",
    "    s3 = get_data(p3)[13:]\n",
    "    l1 = [0]* len(s1)\n",
    "    l2 = [1]* len(s2)\n",
    "    l3 = [2]* len(s3)\n",
    "\n",
    "    # split training and testing data set accordingly \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    X_train, X_test, Y_train, Y_test = split_data(s1,l1,X_train, X_test, Y_train, Y_test)\n",
    "    X_train, X_test, Y_train, Y_test = split_data(s2,l2,X_train, X_test, Y_train, Y_test)\n",
    "    X_train, X_test, Y_train, Y_test = split_data(s3,l3,X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    tokenizer = Tokenizer(oov_token='unk')\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # text tokenize\n",
    "    seq_train = tokenizer.texts_to_sequences(X_train)\n",
    "    seq_test = tokenizer.texts_to_sequences(X_test)\n",
    "    max_sentence_len = 0\n",
    "    for x in seq_train:\n",
    "        length = len(x)\n",
    "        max_sentence_len = length if length > max_sentence_len else max_sentence_len\n",
    "    \n",
    "    training_data = pad_sequences(seq_train, padding='post', maxlen=max_sentence_len)\n",
    "    test_data = pad_sequences(seq_test, padding='post', maxlen=max_sentence_len)\n",
    "    \n",
    "    training_labels = to_categorical(Y_train)\n",
    "    test_labels = to_categorical(Y_test)\n",
    "\n",
    "    return training_data, test_data, training_labels, test_labels, vocab_size, max_sentence_len\n",
    "\n",
    "\n",
    "def cnn_2_layer_model(vocab_size, max_sentence_len):\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, 100, input_length=max_sentence_len))\n",
    "    model.add(layers.Conv1D(128,5))\n",
    "    model.add(layers.MaxPooling1D(3,3, padding='same'))\n",
    "    model.add(layers.Conv1D(64,5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(3, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn_1_layer_model(vocab_size, max_sentence_len):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, 100, input_length=max_sentence_len))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(3, activation='sigmoid'))\n",
    "    adam = keras.optimizers.Adam(lr=0.001,decay=1e-6) # set learning rate to 0.001(which is default)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The result for cnn_1_layer_model:\n",
    "# test loss:0.5594399030183734, \n",
    "# test accuracy: 0.8428394142496701,\n",
    "\n",
    "# The result for cnn_2_layer_model: \n",
    "# test loss: 0.5144588466116973, \n",
    "# test accuracy: 0.8140481509118496\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 20, 100)           5489200   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 5,557,555\n",
      "Trainable params: 5,557,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data, training_labels, test_labels,vocab_size, max_sentence_len = preprocess()\n",
    "model = cnn_1_layer_model(vocab_size, max_sentence_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56403 samples, validate on 24174 samples\n",
      "Epoch 1/5\n",
      "56403/56403 [==============================] - 206s 4ms/step - loss: 0.7072 - acc: 0.7207 - val_loss: 0.4064 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87449, saving model to 1cnn-model.hdf5\n",
      "Epoch 2/5\n",
      "56403/56403 [==============================] - 200s 4ms/step - loss: 0.3819 - acc: 0.8657 - val_loss: 0.2875 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87449 to 0.89745, saving model to 1cnn-model.hdf5\n",
      "Epoch 3/5\n",
      "56403/56403 [==============================] - 178s 3ms/step - loss: 0.2350 - acc: 0.9297 - val_loss: 0.3781 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89745\n",
      "Epoch 4/5\n",
      "56403/56403 [==============================] - 178s 3ms/step - loss: 0.1606 - acc: 0.9556 - val_loss: 0.3302 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89745\n",
      "Epoch 5/5\n",
      "56403/56403 [==============================] - 177s 3ms/step - loss: 0.1192 - acc: 0.9688 - val_loss: 0.3731 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89745\n"
     ]
    }
   ],
   "source": [
    "filepath = \"1cnn-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "history = model.fit(training_data, \n",
    "                    training_labels,\n",
    "                    validation_split=0.3,\n",
    "                    batch_size=50, \n",
    "                    epochs=5, \n",
    "                    callbacks=[checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20145/20145 [==============================] - 3s 156us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_data, test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.578757287553387, 0.850881111941405]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = []\n",
    "for l in test_labels:\n",
    "    tl.append(np.argmax(l))\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == tl[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1,2]\n",
    "res = [correct, wrong]\n",
    "plt.bar(x, res)\n",
    "plt.xticks(x, ('correct', 'wrong'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
